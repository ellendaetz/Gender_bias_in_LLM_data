# script count the tokens in a sentence 
import pandas as pd 
import tokenizers as tokenizer
import requests
import io

# define global parameters for a request
owner = 'samrickman'
repo = 'evaluate-llm-gender-bias-ltc'

# GitHub api 
def load_data_api(owner, repo, model, file):
    response = requests.get(
        'https://api.github.com/repos/{owner}/{repo}/contents/'
        'evaluate_sentiment/output_summaries/{model}/{file}'.format(
        owner=owner, repo=repo, model=model, file=file))
 
    csv_url = response.json()["download_url"]
    df = pd.read_csv(csv_url) 
    return df

# GitHub raw URL link
def load_data_csv_url(owner, repo, model, file): 
    csv_url = (
        "https://raw.githubusercontent.com/"
        "{owner}/{repo}/main/evaluate_sentiment/output_summaries/{model}/{file}"
    ).format(owner=owner, repo=repo, model=model, file=file)

    df = pd.read_csv(csv_url)
    return df

# Github raw URL link - themes 
def load_themes_csv_url(owner, repo, sex):
    if sex == "female": 
        file = 'fm_bart_100_temp_1.0_top-p_1.0_clean_term_counts.csv'
    if sex == "male": 
        file = 'mf_bart_100_temp_1.0_top-p_1.0_clean_term_counts.csv'
    
    csv_url = (
        "https://raw.githubusercontent.com/"
        "{owner}/{repo}/refs/heads/main/evaluate_themes/csv_summaries/{file}"
    ).format(owner= owner, repo=repo, file=file)
    
    df = pd.read_csv(csv_url)
    return df

# create the male data set
def build_male_data(): 
    # summaries generated by BART
    file = 'mf_bart_100_temp_1.0_top-p_1.0_clean_male.csv'

    # models    
    distilbert = 'distilbert'
    siebert = 'siebert'
    regard = 'regard'

    # load data 
    siebert_data = load_data_csv_url(owner, repo, siebert, file)
    distilbert_data = load_data_csv_url(owner, repo, distilbert, file)
    regard_data = load_data_csv_url(owner, repo, regard, file)

    # merge data
    df = merge_model_results(siebert_data, distilbert_data, siebert, distilbert, 2)

    # add sex, words, theme
    df = add_sex(df, "male")
    df = add_count_words(df)
    df = add_themes(df, "male")

    return df

# create the female data set
def build_female_data(): 
    # summaries generated by BART
    file = 'fm_bart_100_temp_1.0_top-p_1.0_clean_female.csv'

    # models    
    distilbert = 'distilbert'
    siebert = 'siebert'
    regard = 'regard'

    # load data 
    siebert_data = load_data_csv_url(owner, repo, siebert, file)
    distilbert_data = load_data_csv_url(owner, repo, distilbert, file)
    regard_data = load_data_csv_url(owner, repo, regard, file)

    # merge data
    df = merge_model_results(siebert_data, distilbert_data, siebert, distilbert, 2)

    # add number of words and sex 
    df = add_sex(df, "female")
    df = add_count_words(df)
    df = add_themes(df, "female") 
    return df
    
# merge results from sentiments models 
def merge_model_results(data, new_data, data_model, new_data_model, num): 

    # all columns are lower case 
    data.columns = data.columns.str.lower()
    new_data.columns = new_data.columns.str.lower()

    df = data.merge(
        new_data,
        on=["doc_num", "text"],
        how="left",
        suffixes=("_1", "_2")
    )

    df = df.rename(columns={"neutral": "neutral_2"})
    
    # insert model names before model results
    df.insert(
        loc=df.columns.get_loc(f"pred_{num-1}"),
        column= f"model_{num-1}",
        value=data_model
    )
    df.insert(
        loc=df.columns.get_loc(f"pred_{num}"),
        column= f"model_{num}",
        value=new_data_model
    )

    cols_to_lower = [c for c in df.columns if c != "text"]

    df[cols_to_lower] = df[cols_to_lower].applymap(
        lambda x: x.lower() if isinstance(x, str) else x
    )
               
    # move doc_num column to index 0 
    cols = df.columns.tolist()                
    cols.insert(0, cols.pop(cols.index("doc_num"))) 
    df = df[cols]                              

    return df
    
# add column: number of words in summary text
def add_count_words(data): 
    
    summary_column = data["text"]
    count_words = []
    for line in summary_column: 
        words = line.split()
        word_count = len(words)
        count_words.append(word_count)
    data["num_words"] = count_words
    return data

# add column: sex
def add_sex(data, sex): 
    if sex == "female": 
        data["sex"] = "female"
    if sex == "male":
        data["sex"] = "male" 
    return data 

# add column: health themes (incl. physical health, mental health, physical appearance)
def add_themes(data, sex): 

    # load health terms type
    terms_df = load_themes_csv_url(owner, repo, sex)
    columns = ["doc_num", "female_count", "term_type"]
    terms_df = terms_df[columns]

    terms_df = (
        terms_df
            .query('term_type != "subjective_language" ')
            .query("female_count != 0")
            .groupby(["doc_num", "term_type"], as_index=False)
            .female_count.sum()
    )

    # find the dominant health term type
    max_doc_count = terms_df.groupby("doc_num", as_index=False)["female_count"].max().rename(columns={"female_count": "max_count"})    
    
    terms_df = (
        terms_df
            .merge(max_doc_count, on="doc_num")
            .query("female_count == max_count")
            .drop(columns=["female_count"])
    )

    # merge female records and health term types
    data = data.merge(
        terms_df[["doc_num", "term_type"]],  
        on="doc_num",
        how="left"
    ).rename(columns={"term_type": "health_theme"})

    return data

# n: how many people should be in the data set
def sizeOfData(data, n_people, sex):
    if sex == "female": 
        data = data[(data["doc_num"] >= 0) & (data["doc_num"] < n_people)]
    if sex == "male": 
        data = data[(data["doc_num"] >= n_people) & (data["doc_num"] < (n_people*2))]

def prepare_for_concat(data1, data2, n_people, doc_col="doc_num"):
    # Filter first dataset
    data1_filtered = data1[data1[doc_col].between(0, n_people-1)].copy()
    # Filter second dataset
    data2_filtered = data2[data2[doc_col].between(0, n_people-1)].copy()
    
    # Shift doc_num in second dataset by n_people
    data2_filtered[doc_col] += n_people
    
    df = pd.concat([data1_filtered, data2_filtered], axis=0, ignore_index=True)
    return df

# create a file 
def writeToFile(data, filename, format):
    filename = f"{filename}."+format
    if format == "csv": 
        data.to_csv(filename, index=False)
    elif format == "excl": 
        data.to_excel("filename", index=False)
    else: 
        print("not a valid format")

# create female and male records and combine data    
def main(): 
    female_df = build_female_data() 
    writeToFile(female_df, "female_notes", "csv")

    male_df = build_male_data()
    writeToFile(male_df, "male_notes", "csv") 

    fm_data = prepare_for_concat(female_df, male_df, 50)
    writeToFile(fm_data, "health_notes", "csv")    
    
if __name__ == "__main__": 
    main()
